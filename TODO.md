## Procesar una web
- [x] Recibir una url y hacer un fetch
- [x] Con la página actual, buscar todas las urls que le pertenecen al mismo dominio
- [x] Revisar todas y cada una de las urls encontradas sin repetir (usando Set)
- [x] Guardar las urls dentro de un json en la carpeta data/{project}/links.json
- [x] Por cada URL revisada, convertir la página a markdown y guardarla en la carpeta data/{project}/pages/{page title}.md
    - [x] ignorar contenido innecesario
        - [x] Footer
        - [x] header
        - [x] forms
        - [x] imagenes
        - [x] links internos (#)
        - [x] elementos vacíos o sin sentido
    - [x] corregir formato de títulos dentro de enlaces
- [ ] Guardar todos los chunks en data/{project}/chunks.json y los embeddings generados en data/{project}/embeddings.json
    - [ ] Implementar servicio de embeddings
    - [ ] Dividir el contenido en chunks significativos
    - [ ] Generar embeddings para cada chunk
    - [ ] Guardar chunks y embeddings en archivos JSON

## Interfaz Web
- [ ] Configurar servidor web con Express/Fastify
    - [ ] Configurar CORS y middleware necesario
    - [ ] Implementar manejo de errores HTTP
    - [ ] Configurar rate limiting
- [ ] Implementar endpoints API REST
    - [ ] POST /api/projects - Crear nuevo proyecto
    - [ ] POST /api/projects/:projectId/crawl - Iniciar crawling
    - [ ] GET /api/projects/:projectId/status - Obtener estado del crawling
    - [ ] GET /api/projects/:projectId/pages - Listar páginas procesadas
    - [ ] GET /api/projects/:projectId/chunks - Obtener chunks generados
- [ ] Crear interfaz de usuario con Astro
    - [ ] Configurar Astro con Tailwind CSS
    - [ ] Crear layouts y componentes base
        - [ ] Layout principal con navegación
        - [ ] Componente de formulario para nueva URL
        - [ ] Componente de progreso de crawling
        - [ ] Componente de previsualización de páginas
    - [ ] Implementar páginas
        - [ ] Página principal con formulario de ingreso de URL
        - [ ] Página de estado del crawling con progreso en tiempo real
        - [ ] Página de listado de páginas procesadas con preview
        - [ ] Página de visualización de chunks y embeddings
    - [ ] Implementar islands para componentes interactivos
        - [ ] Formulario de ingreso con validación
        - [ ] Visualización de progreso en tiempo real
        - [ ] Filtros y búsqueda de páginas procesadas
    - [ ] Diseño responsive y accesible con Tailwind
        - [ ] Sistema de colores y tema
        - [ ] Componentes UI consistentes
        - [ ] Diseño mobile-first
        - [ ] Soporte para modo oscuro
- [ ] Implementar WebSocket para actualizaciones en tiempo real
    - [ ] Notificaciones de progreso del crawling
    - [ ] Estado de generación de embeddings
    - [ ] Errores y advertencias

## Tests Unitarios
- [x] Tests para WebCrawler
    - [x] Inicialización del constructor
    - [x] Crawling de páginas dentro del mismo dominio
    - [x] Respeto de maxDepth
    - [x] Respeto de maxPages
    - [x] Exclusión de URLs por patrón
    - [x] Eliminación de elementos HTML
    - [x] Manejo de errores de red
    - [x] Manejo de HTML inválido
    - [x] Peticiones concurrentes
- [x] Tests para MarkdownConverter
    - [x] Conversión básica de HTML a Markdown
    - [x] Manejo de elementos HTML específicos (headers, lists, code blocks)
    - [x] Limpieza de elementos innecesarios
    - [x] Generación de frontmatter
    - [x] Extracción de metadatos
    - [x] Manejo de errores
    - [x] Formato correcto de títulos dentro de enlaces
- [x] Tests para FileStorage
    - [x] Inicialización del proyecto
    - [x] Creación de directorios
    - [x] Sanitización de nombres de archivo
    - [x] Guardado de archivos Markdown
    - [x] Guardado de archivos JSON
    - [x] Manejo de errores
- [ ] Tests para EmbeddingService (pendiente de implementar)
    - [ ] Generación de embeddings
    - [ ] División en chunks
    - [ ] Guardado de embeddings
    - [ ] Búsqueda por similitud
    - [ ] Manejo de errores

## Generar prompt
- [ ] Dado unos datos ingresados (lead de un cliente) extraer el contenido del mensaje y usarlo para obtener los embeddings del mensaje
- [ ] Usando los embeddings del mensaje buscar dentro de los embeddings del proyecto cuales son los chunks que más se asemejen al mensaje del lead
- [ ] Usar el contenido del lead para extraer el dominio del cliente en el correo electrónico y hacer una búsqueda en internet
    - [ ] Búsqueda en google, ¿existe en los primeros resultados?
    - [ ] Entrar al dominio, petición fetch y obtener el contenido de la página encontrada
        - [ ] Convertirlo a Markdown
        - [ ] Generar un resumen del contenido
- [ ] Dado un prompt principal agregar los datos encontrados prompt + embeddings/chunks encontrados + resumen página + formato correo

## Peticiones recibidas
- [ ] Se reciben leads y se generan los prompts
- [ ] Se realizan las peticiones con el modelo especificado usando el prompt utilizado
- [ ] Todas las peticiones se deben realizar en paralelo
- [ ] La respuesta deberá ser un html correctamente formateado
- [ ] Guardar un log de respuestas dentro de un google sheet

## Mejoras técnicas
- [x] Mover interfaces a archivos específicos en la carpeta types
- [x] Agregar tests unitarios para WebCrawler
- [x] Completar tests unitarios para servicios existentes
- [ ] Implementar manejo de errores más robusto
- [ ] Agregar logging estructurado
- [ ] Mejorar la documentación del código
- [ ] Configurar CI/CD
- [ ] Agregar métricas y monitoreo
- [ ] Dockerizar la aplicación
    - [ ] Crear Dockerfile para el backend
    - [ ] Crear Dockerfile para el frontend
    - [ ] Configurar docker-compose para desarrollo
    - [ ] Configurar docker-compose para producción
